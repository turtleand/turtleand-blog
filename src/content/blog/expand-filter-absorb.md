---
author: Turtleand
pubDatetime: 2026-02-15T18:00:00Z
modDatetime: 2026-02-15T18:00:00Z
title: "Expand, Filter, Absorb: How I Actually Use AI"
slug: expand-filter-absorb
featured: false
draft: false
tags:
  - AI
  - productivity
  - reflection
description: "A simple three-step pattern for using AI as a research amplifier. Expand your search beyond human limits, filter down to signal, and absorb what survives."
---

I wanted to understand OpenClaw Skills. How they work, what people build with them, where the limits are.

Normally I'd open a browser, read three pages, and call it done. Instead, I told my AI agent: "Search everything about OpenClaw Skills. Architecture, examples, limitations, what users complain about, what's undocumented."

It came back with a synthesis of dozens of sources. Forum threads I'd never find. GitHub issues. Docs I didn't know existed.

I read the summary in five minutes. And I got a better picture than I would have after an hour on my own.

## The pattern

Every time I use AI well, I follow the same three steps. I didn't plan it. The pattern just showed up.

**Expand.** Ask the AI to go wide. Not "find me an answer" but "explore this whole space." I want angles I wouldn't think of. Sources I'd skip. The AI doesn't get tired after page three. It just keeps going.

This is the part that's new. We've always been able to search. But expanding your search space across dozens of sources, comparing them, catching contradictions? That used to take hours of focused work. Now you describe what you want and the AI covers the ground for you.

**Filter.** Now there's too much. So I ask the AI to reduce it. Summarize. Compare. Rank by relevance. Strip the noise. Give me the signal.

This is where most people stop too early. They get raw results and try to process everything themselves. But you already have a machine that reads faster than you. Let it.

**Absorb.** This is where I come back in. I read the filtered output. Sometimes I listen to it as voice notes while I walk. And something happens that the AI can't do: I connect it to things I already know. I feel which parts matter for my specific situation.

The AI can tell me what experts think. It can't tell me which insight changes my next project. That's still my job.

## It's like asking AI to write the prompt

Here's a parallel that clicked for me. When you want a good AI prompt, the smartest move isn't writing it yourself. It's asking the AI: "Write me the best prompt for X." The AI knows its own format better than you do.

Same thing with research. The smartest move isn't searching yourself. It's telling the AI what you want to understand, and letting it figure out where to look and how to organize what it finds.

In both cases you're doing the same thing: using AI for the mechanical part so you can focus on the judgment part.

## Fun fact from my CS background

If you've worked with distributed systems, this pattern might ring a bell. Google's MapReduce framework from 2004 did something similar: spread work across many machines (map), then combine results (reduce).

Expand, Filter, Absorb is basically MapReduce for your brain. Except MapReduce was missing the "expand" step. It processes data you already have. This pattern starts by going out and finding data you didn't know existed.

Small difference. Big deal in practice.

## Try it once

Pick something you're curious about. Don't search for it yourself. Tell your AI to go wide. Then ask it to compress. Then read what survives.

The tools will change. This specific AI will be outdated eventually. But the framework stays. Expand what you can see. Filter what you don't need. Absorb what matters.

It's just easier now to do what was always hard to do manually.
